What are Sockets?
- Sockets are a method of Inter Process Communication that allows data to be exchanged b/w applications running on 
same host or different hosts.
- A Socket is simply a file descriptor which can be obtained using socket(), system call.
ex:
fd = socket();
- Any socket is described by 5-tuples:
      a: Sender IP.
	  b: Sender Port.
	  c: Receiver IP.
	  d: Receiver Port.
	  e: Communication protocol(TCP/UDP)
These should be unique, through out the system. i.e No two sockets can have exactly same tuple values.       

There are several types of sockets, like: Unix Domain Sockets, Raw Sockets and Internet Sockets.
But, we will be concentrating only on Internet Sockets as of now. As its the most widely used socket type.  

Internet Sockets:
--------------------------------------------------------------------------------------------------	  
- The Internet Sockets can be divided into two types:
    1. Stream Sockets   AKA (SOCK_STREAM)
    2. Datagram Sockets	AKA (SOCK_DGRAM)
 
Stream Sockets (SOCK_STREAM):
------------------------------
Stream sockets are reliable, bi-directional, connection oriented byte stream.

Stream sockets make use of TCP/IP protocol stack.

 - Reliable => Means, if the data is sent, either it will be success or error. i.e no loss of packets.
               Data maintains correct sequencing i.e if we send 123 it will appear at receiver as 123 and 312 or 132.
 
 - Bi-directional => Means, data can be transmitted in either directions.

 - Byte-stream => Means, as with pipes there is no concept of message boundaries.
 
 - Connection oriented => connection is maintained b/w client and server. 
        

Datagram sockets (SOCK_DGRAM):
-------------------------------
Datagram sockets are non-reliable, connection less packets of data.

packets of data => Means, unlike byte-stream there exists message boundaries.
connectionless => No connection is maintained b/w sender and receiver. Its simply a fire and forget strategy.
Non-Reliable => You cannot rely on sequencing of data at receiver end. Also, packet loss can occur.
 
Datagram sockets make use of UDP/IP protocol stack.

Some applications making use of Datagram sockets are: dhcp, ping

Ports:
--------------------
A socket on its own cannot communicate with outside world. It needs the help of something called ports to do so.
The main usage of port is to allow multiple services to run on single system. We will see how ports helps us to do so in just a minute.
Ports are identified by 16-bit numbers called Port Numbers.
No two ports residing on the same system can share same port Number.  
NOTE: All ports under 1024 are reserved for root user.
They are used in conjunction with IP addresses as a socket identifier. (For both TCP and UDP)

What if there were no ports and only Ip addresses?
Ans: 
  In such a case a socket can only be identified by 3-tuple i.e sourceIP:DestinationIP:Protocol. 
  Thus, if two applications say mysql and apache needs to execute on same machine
  they cannot, as both will have same protocol i.e TCP and will have same sourceIP to bind to. 
Thus, ports helps us to run multiple services on same machine by binding them to different ports.  

Ephemeral ports: 
  In case a client application does not explicitely binds itself to a port. 
  Then, automatically an available port is assigned by kernel to the application for sending request to server such
a port is called ephemeral port.
Ephemeral port range can be obtained from file: /proc/sys/net/ipv4/ip_local_port_range 

RelationShip b/w ports and sockets:
---------------------------------------
See Fig.

Following are the system calls that we need to understand before checking out how a client/server can be created.

Socket System Calls:
--------------------------------------------------------------------------------------
1. socket() :=>
   This system call is used to create a new socket and returns the file descriptor for the created socket. 
   The call has following signature:
    `int socket(int domain, int type, int protocol);` 
 - domain can be:
    AF_UNIX => For communication b/w applications on same host. (i.e Unix Domain Sockets)
    AF_INET => communication using IPv4 addressing.
    AF_INET6 => communication using IPv6 addressing.

 - type specifies: Whether its a stream socket(SOCK_STREAM) or datagram(SOCK_DGRAM) socket.
 - protocol: This can simply be set to 0 and it will automatically chose correct protocol based on type specified (TCP/UDP).

2. bind() :=> 
  Now, that you have got the socket. 
  Next step is to specify the IP and Port to which you want to bind this socket. This is done using bind() system call.
   The call has following signature:
   `int bind(int sockfd, struct sockaddr *my_addr, int addrlen);`
    - sockfd => file descriptor obtained from socket() call.
    - sockaddr => IP:Port to bind.
   NOTE: All ports under 1024 are reserved for root user.
   
   TIP: Sometimes, you will see that bind() failes with an error "Address already in use" but actually there is no application using the port. This happens because the application
        has ended, however still the socket binded to port is hanging in kernel. Such a hogging port will automatically get cleared in a minute or so. But if you want to totally remove
        this situation you can add option 'SO_REUSEADDR' in socket options.		
		
3. connect() :=> (Usedonly by clients) 
   Now, we have created a socket, binded that socket to an Ip:Port, its time to use this binding and connect to remote host. 
   This is done via connect() system call.
   Connect() syscall is used by clients in client-server paradigm.
   The call has following signature:
         `int connect(int sockfd, struct sockaddr *serv_addr, int addrlen);`
          - sockfd => file descriptor obtained from socket() call.
          - sockaddr => Ip:PORT address of remote host.
      NOTE: We can also call connect() without making an explicit call to bind(). 
        In such a case, connect will automatically call bind() internally and will choose a random (ephemeral) port to bind socket to. 		  
	  NOTE: connect() is a blocking call and will block incase servers backlog Q is full, 
         till server inserts the connection in backlog Q. See accept().
	  NOTE: For TCP sockets, connections are queued to baclog Q only after handshake is completed by kernel.
	
4. listen()	:=> (used only by servers)
   Incase, we are building a server we need to listen for incoming connections on a port. This is done via listen() system call.
   The call has following signature:          
     `int listen(int sockfd, int backlog);`
			 - sockfd  => file descriptor obtained from socket() call.
			 - backlog =>  Size of queue in which connections will wait till they are marked as accepted. Default is 20.
	  So, for the server to listen for incoming connections following is the system call sequencing:
	       socket() -> bind() -> listen().
		   NOTE: listen() syscall is always non-blocking.
		   
5. accept() :=> 
We don't want incoming connections to keep waiting in backlog, so we use accept() system call to pick a connection from backlog queue.
Along with picking a connection and returning it to us, the accept() call does some extra work too. 
It creates a new socket for the returned connection and this new socket is used for any communication b/w the server and returned client connection. while, The old socket keeps on listening for more client connections. 
We need to call accept() in loop so that the program picks next connection once previous is accepted.
Thus, if we have 10 active client connections we have 10+1 sockets. Where 1 (original) socket is listening for more clients and remaining 10 are serving I/O.
 The call has following signature:				
       `int accept(int sockfd, struct sockaddr *addr, socklen_t *addrlen);`
                  - sockfd => original socket descriptor obtained using socket() call.
                  - sockaddr => you dont need to fill this, it will be filled with client Ip and POrt once accept is called. 
				  
NOTE: accept() does not opens up a new port on host. It just returns a new socket which uses the servers binded port for communication.
NOTE: accept() is a blocking call and will block if backlog queue is empty.				  

6. send() and recv() :=> These syscalls are used to send and receive data from stream sockets. For datagram sockets use receivefrom() and sendto()
                        NOTE: These needs to be called on new socket descriptor returned from accept() call not on listening socket.
                        NOTE: recv() is a blocking call and will block till first byte is received.
 NOTE: read/write syscalls and send/recv syscalls both fundamentally does the same thing.
  The only difference is that send/recv calls provide some specific
  features that can be enabled by passing appropriate flags to function calls.However, incase no flag is passed they behave exactly same as read/write calls. 

7. close() :=> Closes the socket connection and sends EOF.
						
						
//@todo make a good figure to illustrate above client and server steps described above.						
						
						
Active vs Passive socket:
-----------------------------
Active: Any socket that can initiate a connection to another socket is called active sockets. ex: sockets opened by client programs and sockets created by accept() call.
Passive: Any socket that can only listen to incoming requests from other sockets but cannot initiate a connection is called passive socket. ex: listening sockets 
opened by server programs.

Blocking nature of calls:
----------------------------------
Connect() -> blocks. The kernel sends the SYN packet to server and blocks till a SYNC ACK is received. 
Accept() -> blocks if backlogQ is empty i.e no client connection is waiting to be accepted. (Needs to be called in loop)
Read() -> Blocks till atleast 1 byte is read from remote end.
Needs to be called in loop in order to read full data. But the problem is how will it know that it has read full data
and now needs to break out of loop as no more data will be sent via server. 
For this, we can use a delimeter byte and upon encountering that byte we can assume that full data has been transfered.Generally \n is used as delimeter byte.
NOTE: we cannot use EOF, as EOF occurs only if remote end closes connection.
Write() -> write call blocks if the TCP send buffer is full. 

Client/Server Design:
------------------------
Below figure illustrates the lifecycle of communication b/w a single client and server.


close() vs shutdown() syscalls behavioral differences:
--------------------------------------------------------
The difference between close() and shutdown() is that, upon calling close() the socket is closed for both read/write operations.
However, when calling shutdown() you can specify whether you need to close the connection only for write operations or read operations or both.

Another major difference b/w the two is that, upon calling close() on a file descriptor only that particular file descriptor is closed and
any copies of that file descriptor remains in function as it is.
ex: fd2 = dup(sockfd);
    close(sockfd);
//In this case, you can perform operations using fd2 even though sockfd is closed.
However, for ex:
     fd2 = dup(sockfd);
     shutdown(sockfd); 	
//In this case you cannot perform operations on either of fd2 or sockfd.

Note: Shutdown() does not closes the file descriptor, it only restricts further operations on it. SO, even though you have called shutdown() it is mandatory 
to call close() inorder to eventually close the file descriptor.  

sendfile() syscall:
-------------------------------------------------------------
Incase you need to transfer contents of a file through socket and the file is stored in disk, you will need to do something like this:
    while ((n = read(diskfilefd, buf, BUZ_SIZE)) > 0)
         write(sockfd, buf, n);
This is not a very optimized solution for large files, as each loop iteration requires atleast two system calls to be executed.	
 - read() := syscall reads the chunk from kernel buffer to user space
 - write():= syscall writes the data to kernel buffer.
Following is the visualization of the above scenario:
Fig pg: 1261
sendfile() syscall provides a way to do all of the above described task in single syscall:
      sendfile(in, out)
Following is the visualization of the same:
Fig pg: 1261	  
 
Types of Server Designs (Traditional):
---------------------------------------

Servers can be placed into different categories based on how they handle client connections:

1. Iterative Server: 
      - It is a server design that process one client request at a time.
      - There is a single process, which waits for incoming connections, once a connection request is recieved it creates
        a communication channel for that connection request using accept() syscall and then sends and receive data on that connection.
        Once the communication is done it closes the connection and then only picks up the next request.
        Thus, the second client needs to wait till the request of first client is fully answered.
        Fig: needed. 

2. Concurrent Server:
      Since it is evident that Iterative server design is not very ideal approach to handle multiple client requests. We have concurrent server
      approach, In this multiple clients are processed using the multiprocess or multi threading approach.
      - There is a master process whose job is to listen for incoming connection requests. Upon obtaining a connection request, it creates
      a child process/ thread to handle all communication for that particular request. And itself goes on to pick another connection request.
      Thus all client requests are processed by seperate child process/threads.
      Fig: needed.

Modern Server Design:
------------------------------------
The Concurrent Server design was introduced to overcome the problems of Iterative design. But over the time, as the traffic grew
and the need for more concurrency arrived it became evident that Concurrent server design is not sufficient. Because, forking a lot of threads/
child processes takes up additional resources. 
Eventhough, the threads takes up considerably less resources than child processes, they have their own set of problems, like: the locking
needs to be done to use shared memory area which degrades performance.

Thus a better approach was needed, and in search of it somebody decided to make use of Non-Blocking feature of syscalls.
Till now we have learned that Accept() and Read() calls are blocking calls, but what if there is a way to make them NOT BLOCK.
Yes, we can setup flags to make these calls Non-Blocking in Nature so that instead of blocking they returns with an error EAGAIN, if they have
nothing to do.

Using the Non-blocking feature following server design can be implemented.
Fig: Need too make a figure to illustrate non-blocking feature and the problem it presents.

However, such a design has its own problems. The major problem is that, how will you get to know that an incoming connection request has arrived
or there is data to be read from socket. For this, you will need to continuosly loop over Accept() and Read() calls to keep checking for
any state changes, this wastes cpu time as the cpu will be continuosly on load. The above figure illustrates this problem.

The solution is to use select(), poll() and epoll() syscalls. The primary objective of these syscalls is to monitor multiple socket/pipe descriptors
and notify for events such as: 
 - When new connection arrives.
 - When data is avilable for Reading.
 - When buffer is ready to receive data 
and so on.

Lets see these calls in detail and observe the functional difference b/w them.

select(), poll() vs epoll():
------------------------------
The select() and poll() system calls have been present on UNIX system for years. Thus most of the Unix and Linux systems support them.
However, they have a scalibility problem. They can't monitor large number (several hundreds) of socket descriptors. 

The epoll() system call can handle large number of descriptors but it is Linux specific and is not implemented by other Unix systems. Some of the systems
implement a similar variant of this called "kqueue".

Generally, people build systems in such a manner that they use epoll or kqueue by default and if system does not supports them, they fallback to 
select or poll techniques.

NOTE: There is a libevent library which provides an interface over these calls. It choses the best method to use as per the OS.  
   http://libevent.org/































































#############################################################################################s

SEE section 61.
system limits:
https://unix.stackexchange.com/questions/12985/how-to-check-rx-ring-max-backlog-and-max-syn-backlog-size

TCP Socket Backlog Q size => Imp as if Q is full connections need to wait and may be discarded too. 
ss -t -l => Send-Q shows the max size.
Also, max size can be seen in /proc/sys/net/core/somaxconn
ss -lti '( sport = :http )' => unacked column shows rejected requests due to backlog queue fill up.


MTU => data is broken into frames of this size by network interface before sending to physical layer. Can be seen in ifconfig.MTU is in bytes
Ephemeral port range: /proc/sys/net/ipv4/ip_local_port_range 
Topics:
How is the server chosen when getaddrinfo() returns multiple ips.
Ans: First is chosen if first doesnot work it goes to second one.
[`dnsmasq` automatically round robins b/w returned ips, so even if dns result is cached round robin works]   

Good read on scalability.
https://github.com/binhnguyennus/awesome-scalability 

https://blog.packagecloud.io/eng/2016/06/22/monitoring-tuning-linux-networking-stack-receiving-data/

TCP backlog working:
http://veithen.github.io/2014/01/01/how-tcp-backlog-works-in-linux.html

standard tcp states?











//todo: tcpcork/tcpnodelay socket option? //Seems a good option need to read few blogs:
http://baus.net/on-tcp_cork
//todo: what is nagle algorithm and how its related to these options.??
//todo: flags accepted by send/recv call.




---------------------------------------------------------------------------------------------------------------
//todo: write about dns functions
//todo: create an iterative server that distributes random integers to its clients.










































































































































































